{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c2071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225745, 79)\n",
      "(286467, 79)\n",
      "(191033, 79)\n",
      "(529918, 79)\n",
      "(288602, 79)\n",
      "(170366, 79)\n",
      "(445909, 79)\n",
      "(692703, 79)\n",
      "Read 2830743 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>...</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54865</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55054</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55055</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46236</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54863</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Destination Port   Flow Duration  ...   Idle Min   Label\n",
       "0              54865               3  ...          0  BENIGN\n",
       "1              55054             109  ...          0  BENIGN\n",
       "2              55055              52  ...          0  BENIGN\n",
       "3              46236              34  ...          0  BENIGN\n",
       "4              54863               3  ...          0  BENIGN\n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import glob\n",
    "\n",
    "#path = r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE' \n",
    "#all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "#li = []\n",
    "\n",
    "#for filename in all_files:\n",
    "   # df = pd.read_csv(filename, index_col=None, header=0)\n",
    "   # li.append(df)\n",
    "\n",
    "#frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "df0 = pd.read_csv(r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE\\Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv')\n",
    "df1 = pd.read_csv(r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE\\Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv')\n",
    "\n",
    "df2 = pd.read_csv(r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE\\Friday-WorkingHours-Morning.pcap_ISCX.csv')\n",
    "\n",
    "df3 = pd.read_csv(r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE\\Monday-WorkingHours.pcap_ISCX.csv')\n",
    "\n",
    "df4 = pd.read_csv(r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE\\Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv')\n",
    "\n",
    "df5 = pd.read_csv(r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE\\Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv')\n",
    "df6 = pd.read_csv(r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE\\Tuesday-WorkingHours.pcap_ISCX.csv')\n",
    "\n",
    "df7 = pd.read_csv(r'C:\\Users\\abhiw\\Downloads\\cicids2017\\MachineLearningCSV\\MachineLearningCVE\\Wednesday-workingHours.pcap_ISCX.csv')\n",
    "\n",
    "print(df0.shape)\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)\n",
    "print(df5.shape)\n",
    "print(df6.shape)\n",
    "print(df7.shape)\n",
    "\n",
    "data = [df0,df1,df2,df3,df4,df5,df6,df7]\n",
    "df  = pd.concat(data)\n",
    "\n",
    "print(\"Read {} rows.\".format(len(df)))\n",
    "df.dropna(inplace=True,axis=1)\n",
    "\n",
    "pd.set_option('display.max_columns', 5)\n",
    "pd.set_option('display.max_rows', 5)\n",
    "# display 5 rows\n",
    "display(df[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b830fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def expand_categories(values):\n",
    "    result = []\n",
    "    s = values.value_counts()\n",
    "    t = float(len(values))\n",
    "    for v in s.index:\n",
    "        result.append(\"{}:{}%\".format(v,round(100*(s[v]/t),2)))\n",
    "    return \"[{}]\".format(\",\".join(result))\n",
    "        \n",
    "def analyze(df):\n",
    "    print()\n",
    "    cols = df.columns.values\n",
    "    total = float(len(df))\n",
    "\n",
    "    print(\"{} rows\".format(int(total)))\n",
    "    for col in cols:\n",
    "        uniques = df[col].unique()\n",
    "        unique_count = len(uniques)\n",
    "        if unique_count>100:\n",
    "            print(\"** {}:{} ({}%)\".format(col,unique_count,int(((unique_count)/total)*100)))\n",
    "        else:\n",
    "            print(\"** {}:{}\".format(col,expand_categories(df[col])))\n",
    "            expand_categories(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8969413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2830743 rows\n",
      "**  Destination Port:53805 (1%)\n",
      "**  Flow Duration:1050899 (37%)\n",
      "**  Total Fwd Packets:1432 (0%)\n",
      "**  Total Backward Packets:1747 (0%)\n",
      "** Total Length of Fwd Packets:17928 (0%)\n",
      "**  Total Length of Bwd Packets:64698 (2%)\n",
      "**  Fwd Packet Length Max:5279 (0%)\n",
      "**  Fwd Packet Length Min:384 (0%)\n",
      "**  Fwd Packet Length Mean:99716 (3%)\n",
      "**  Fwd Packet Length Std:253909 (8%)\n",
      "** Bwd Packet Length Max:4838 (0%)\n",
      "**  Bwd Packet Length Min:583 (0%)\n",
      "**  Bwd Packet Length Mean:147614 (5%)\n",
      "**  Bwd Packet Length Std:248869 (8%)\n",
      "**  Flow Packets/s:1240164 (43%)\n",
      "**  Flow IAT Mean:1166311 (41%)\n",
      "**  Flow IAT Std:1056642 (37%)\n",
      "**  Flow IAT Max:580289 (20%)\n",
      "**  Flow IAT Min:136316 (4%)\n",
      "** Fwd IAT Total:493098 (17%)\n",
      "**  Fwd IAT Mean:737737 (26%)\n",
      "**  Fwd IAT Std:700313 (24%)\n",
      "**  Fwd IAT Max:437316 (15%)\n",
      "**  Fwd IAT Min:110631 (3%)\n",
      "** Bwd IAT Total:414928 (14%)\n",
      "**  Bwd IAT Mean:670824 (23%)\n",
      "**  Bwd IAT Std:709042 (25%)\n",
      "**  Bwd IAT Max:368285 (13%)\n",
      "**  Bwd IAT Min:66074 (2%)\n",
      "** Fwd PSH Flags:[0:95.36%,1:4.64%]\n",
      "**  Bwd PSH Flags:[0:100.0%]\n",
      "**  Fwd URG Flags:[0:99.99%,1:0.01%]\n",
      "**  Bwd URG Flags:[0:100.0%]\n",
      "**  Fwd Header Length:3771 (0%)\n",
      "**  Bwd Header Length:3945 (0%)\n",
      "** Fwd Packets/s:1220423 (43%)\n",
      "**  Bwd Packets/s:1107886 (39%)\n",
      "**  Min Packet Length:215 (0%)\n",
      "**  Max Packet Length:5708 (0%)\n",
      "**  Packet Length Mean:215826 (7%)\n",
      "**  Packet Length Std:412246 (14%)\n",
      "**  Packet Length Variance:405565 (14%)\n",
      "** FIN Flag Count:[0:96.46%,1:3.54%]\n",
      "**  SYN Flag Count:[0:95.36%,1:4.64%]\n",
      "**  RST Flag Count:[0:99.98%,1:0.02%]\n",
      "**  PSH Flag Count:[0:70.19%,1:29.81%]\n",
      "**  ACK Flag Count:[0:68.42%,1:31.58%]\n",
      "**  URG Flag Count:[0:90.52%,1:9.48%]\n",
      "**  CWE Flag Count:[0:99.99%,1:0.01%]\n",
      "**  ECE Flag Count:[0:99.98%,1:0.02%]\n",
      "**  Down/Up Ratio:[1:60.24%,0:37.03%,2:1.77%,5:0.38%,3:0.23%,6:0.23%,4:0.1%,7:0.02%,8:0.0%,29:0.0%,9:0.0%,10:0.0%,12:0.0%,27:0.0%,25:0.0%,43:0.0%,11:0.0%,39:0.0%,32:0.0%,90:0.0%,74:0.0%,108:0.0%,124:0.0%,20:0.0%,35:0.0%,28:0.0%,26:0.0%,21:0.0%,16:0.0%,14:0.0%,156:0.0%]\n",
      "**  Average Packet Size:212207 (7%)\n",
      "**  Avg Fwd Segment Size:99716 (3%)\n",
      "**  Avg Bwd Segment Size:147611 (5%)\n",
      "**  Fwd Header Length.1:3771 (0%)\n",
      "** Fwd Avg Bytes/Bulk:[0:100.0%]\n",
      "**  Fwd Avg Packets/Bulk:[0:100.0%]\n",
      "**  Fwd Avg Bulk Rate:[0:100.0%]\n",
      "**  Bwd Avg Bytes/Bulk:[0:100.0%]\n",
      "**  Bwd Avg Packets/Bulk:[0:100.0%]\n",
      "** Bwd Avg Bulk Rate:[0:100.0%]\n",
      "** Subflow Fwd Packets:1432 (0%)\n",
      "**  Subflow Fwd Bytes:17928 (0%)\n",
      "**  Subflow Bwd Packets:1747 (0%)\n",
      "**  Subflow Bwd Bytes:64738 (2%)\n",
      "** Init_Win_bytes_forward:12151 (0%)\n",
      "**  Init_Win_bytes_backward:13112 (0%)\n",
      "**  act_data_pkt_fwd:1093 (0%)\n",
      "**  min_seg_size_forward:[20:48.94%,32:40.82%,24:4.99%,40:4.73%,44:0.28%,28:0.16%,0:0.06%,56:0.0%,36:0.0%,60:0.0%,48:0.0%,52:0.0%,8:0.0%,-83885313:0.0%,14:0.0%,6:0.0%,-536870660:0.0%,12:0.0%,78:0.0%,93:0.0%,46:0.0%,10:0.0%,138:0.0%,31:0.0%,-536870661:0.0%,38:0.0%,126:0.0%,-1:0.0%]\n",
      "** Active Mean:326325 (11%)\n",
      "**  Active Std:202826 (7%)\n",
      "**  Active Max:299565 (10%)\n",
      "**  Active Min:175670 (6%)\n",
      "** Idle Mean:222016 (7%)\n",
      "**  Idle Std:197616 (6%)\n",
      "**  Idle Max:149737 (5%)\n",
      "**  Idle Min:223888 (7%)\n",
      "**  Label:[BENIGN:80.3%,DoS Hulk:8.16%,PortScan:5.61%,DDoS:4.52%,DoS GoldenEye:0.36%,FTP-Patator:0.28%,SSH-Patator:0.21%,DoS slowloris:0.2%,DoS Slowhttptest:0.19%,Bot:0.07%,Web Attack � Brute Force:0.05%,Web Attack � XSS:0.02%,Infiltration:0.0%,Web Attack � Sql Injection:0.0%,Heartbleed:0.0%]\n"
     ]
    }
   ],
   "source": [
    "analyze(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e61b19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "    \n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = f\"{name}-{x}\"\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcb3a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if i ==' Label':\n",
    "        continue\n",
    "    else:\n",
    "        encode_numeric_zscore(df, i)\n",
    "        \n",
    "df.dropna(inplace=True,axis=1)\n",
    "df[0:5]\n",
    "\n",
    "x_columns = df.columns.drop(' Label')\n",
    "x = df[x_columns].values\n",
    "dummies = pd.get_dummies(df[' Label'])\n",
    "outcomes = dummies.columns\n",
    "num_classes = len(outcomes)\n",
    "y = dummies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1f2e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Label\n",
       "BENIGN                        2273097\n",
       "Bot                              1966\n",
       "                               ...   \n",
       "Web Attack � Sql Injection         21\n",
       "Web Attack � XSS                  652\n",
       "Name:  Label, Length: 15, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(' Label')[' Label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3b14d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2123057 samples, validate on 707686 samples\n",
      "Epoch 1/1000\n",
      "2123057/2123057 - 283s - loss: 0.2189 - val_loss: 0.1620\n",
      "Epoch 2/1000\n",
      "2123057/2123057 - 217s - loss: 0.1634 - val_loss: 0.1495\n",
      "Epoch 3/1000\n",
      "2123057/2123057 - 207s - loss: 0.1534 - val_loss: 0.1462\n",
      "Epoch 4/1000\n",
      "2123057/2123057 - 196s - loss: 0.1460 - val_loss: 0.1405\n",
      "Epoch 5/1000\n",
      "2123057/2123057 - 210s - loss: 0.1384 - val_loss: 0.1689\n",
      "Epoch 6/1000\n",
      "2123057/2123057 - 204s - loss: 0.1293 - val_loss: 0.1212\n",
      "Epoch 7/1000\n",
      "2123057/2123057 - 229s - loss: 0.1310 - val_loss: 0.1150\n",
      "Epoch 8/1000\n",
      "2123057/2123057 - 229s - loss: 0.1284 - val_loss: 0.1267\n",
      "Epoch 9/1000\n",
      "2123057/2123057 - 219s - loss: 0.1252 - val_loss: 0.1178\n",
      "Epoch 10/1000\n",
      "2123057/2123057 - 231s - loss: 0.1225 - val_loss: 0.1224\n",
      "Epoch 11/1000\n",
      "2123057/2123057 - 231s - loss: 0.1219 - val_loss: 0.1217\n",
      "Epoch 12/1000\n",
      "2123057/2123057 - 226s - loss: 0.1207 - val_loss: 0.1108\n",
      "Epoch 13/1000\n",
      "2123057/2123057 - 224s - loss: 0.1187 - val_loss: 0.0996\n",
      "Epoch 14/1000\n",
      "2123057/2123057 - 229s - loss: 0.1205 - val_loss: 0.1316\n",
      "Epoch 15/1000\n",
      "2123057/2123057 - 226s - loss: 0.1242 - val_loss: 0.1319\n",
      "Epoch 16/1000\n",
      "2123057/2123057 - 228s - loss: 0.1274 - val_loss: 0.1131\n",
      "Epoch 17/1000\n",
      "2123057/2123057 - 228s - loss: 0.1240 - val_loss: 0.1287\n",
      "Epoch 18/1000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "2123057/2123057 - 203s - loss: 0.1307 - val_loss: 0.1284\n",
      "Epoch 00018: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b0207abe08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(50, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.add(Dense(y.shape[1],activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
    "                        patience=5, verbose=1, mode='auto',\n",
    "                           restore_best_weights=True)\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
    "          callbacks=[monitor],verbose=2,epochs=1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80877227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.9768343587410235\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "y_eval = np.argmax(y_test,axis=1)\n",
    "score = metrics.accuracy_score(y_eval, pred)\n",
    "print(\"Validation score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43281b45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
